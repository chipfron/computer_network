# 5.1 运输层协议概述
## 5.1.1 进程之间的通信
- **运输层向它上面的应用层提供通信服务**，它属于面向通信部分的最高层，同时也是用户功能中的最低层。当网络的边缘部分中的两台主机使用网络的核心部分的功能进行端到端的通信时，只有主机的协议栈才有运输层，而网络核心部分中的路由器在转发分组时都只用到下三层的功能。
- 真正进行通信的实体是在主机中的进程，是这台主机中的一个**进程**和另一台主机中的一个**进程**在交换数据。因此，两台主机进行通信就是两台主机中的**应用进程互相通信**。IP协议虽然能把分组送到目的主机，但是这个分组还停留在主机的网络层而没有交付主机中的应用进程。从运输层的角度看，**通信的真正端点并不是主机而是主机中的进程**。也就是说，**端到端的通信**是应用进程之间的通信。
- 运输层有一个很重要的功能——**复用**和**分用**。这里的“复用”是指在发送方不同的应用进程都可以使用同一个运输层协议传送数据（当然需要加上适当的首部），而“分用”是指接收方的运输层在剥去报文的首部后能够把这些数据正确交付目的应用进程。
- **运输层提供应用进程间的逻辑通信**”。“逻辑通信”的意思是：从应用层来看，只要把应用层报文交给下面的运输层，运输层就可以把这报文传送到对方的运输层，**好像这种通信就是沿水平方向直接传送数据。但事实上这两个运输层之间并没有一条水平方向的物理连接。数据的传送是沿着图中的虚线方向（经过多个层次）传送的**。“逻辑通信”的意思是“好像是这样通信，但事实上并非真的这样通信”。
- **网络层为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信**。
- 根据应用程序的不同需求，运输层需要有两种不同的运输协议，即**面向连接的TCP** 和**无连接的UDP**。
- **运输层向高层用户屏蔽了下面网络核心的细节**（如网络拓扑、所采用的路由选择协议等），**它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道**，但这条逻辑通信信道对上层的表现却因运输层使用的不同协议而有很大的差别。当运输层**采用面向连接的TCP协议时，尽管下面的网络是不可靠的**，但这种逻辑通信信道就相当于**一条全双工的可靠信道**。但当运输层采用无连接的UDP协议时，这种逻辑通信信道仍然是一条**不可靠信道**。
## 5.1.2 运输层的两个主要协议
- TCP/IP运输层的两个主要协议都是互联网的正式标准，即：
	1. **用户数据报协议** UDP
	2. **传输控制协议** TCP
- 图5-3给出了这两种协议在协议栈中的位置。
	1. ![[Pasted image 20230807163232.png]]
- 两个对等运输实体在通信时传送的数据单位叫做**运输协议数据单元** TPDU。但在TCP/IP体系中，则根据所使用的协议是TCP或UDP，分别称之为**TCP报文段**或**UDP用户数据报**
- UDP在传送数据之前**不需要先建立连接**。远地主机的运输层在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP却是一种最有效的工作方式。
- TCP则**提供面向连接的服务**。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP不提供广播或多播服务。由于TCP要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。
- 表5-1给出了一些应用和应用层协议主要使用的运输层协议（UDP或TCP）。
	1. ![[Pasted image 20230807163339.png]]
## 5.1.3 运输层的端口
- 应用层所有的应用进程都可以通过运输层再传送到IP层（网络层），这就是**复用**。运输层从IP层收到发送给各应用进程的数据后，必须分别交付指明的各应用进程，这就是**分用**。给应用层的每个应用进程赋予一个非常明确的标志是至关重要的。
- 进程的创建和撤销都是动态的，通信的一方几乎无法识别对方机器上的进程。另外，我们往往需要利用目的主机提供的功能来识别终点，而不需要知道具体实现这个功能的进程是哪一个。
- 通信的终点是应用进程，但只要把所传送的报文交到目的主机的某个合适的目的端口，剩下的工作（即最后交付目的进程）就由TCP或UDP来完成。
- **在协议栈层间的抽象的协议端口是软件端口**，和路由器或交换机上的硬件端口是完全不同的概念。硬件端口是**不同硬件设备**进行交互的接口，而**软件端口是应用层的各种协议进程与运输实体进行层间交互的一种地址**。不同的系统具体实现端口的方法可以是不同的（取决于系统使用的操作系统）。
- 当运输层收到IP层交上来的运输层报文时，就能够根据其首部中的目的端口号把数据交付应用层的目的应用进程。
- **端口号只具有本地意义**，它只是为了标志**本计算机**应用层中的各个进程在和运输层交互时的层间接口。在互联网不同计算机中，相同的端口号是**没有关联**的。
- 两个计算机中的进程要互相通信，不仅必须知道对方的IP地址（为了找到对方的计算机），而且要知道对方的端口号（为了找到对方计算机中的应用进程）。
- 运输层的端口号分为下面的两大类：
	1. **服务器端使用的端口号** 　最重要的一类叫做**熟知端口号**或**系统端口号**。IANA把这些端口号指派给了TCP/IP最重要的一些应用程序，让所有的用户都知道。当一种新的应用程序出现后，IANA必须为它指派一个熟知端口，否则互联网上的其他应用进程就无法和它进行通信；另一类叫做**登记端口**号。这类端口号是为没有熟知端口号的应用程序使用的。使用这类端口号必须在IANA按照规定的手续登记，以防止重复。
	2. **客户端使用的端口号** 　由于这类端口号仅在客户进程运行时才动态选择，因此又叫做**短暂端口号**。这类端口号留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的端口号，因而可以把数据发送给客户进程。通信结束后，刚才已使用过的客户端口号就不复存在，这个端口号就可以供其他客户进程使用。
# 5.2 用户数据报协议UDP
## 5.2.1 UDP概述
- 用户数据报协议UDP只在IP的数据报服务之上增加了很少一点的功能，这就是复用和分用的功能以及差错检测的功能。UDP的主要特点是：
	1. UDP是**无连接的**，即发送数据之前不需要建立连接，因此减少了开销和发送数据之前的时延。
	2. UDP使用**尽最大努力交付**，即不保证可靠交付，因此主机不需要维持复杂的连接状态表。
	3. UDP是**面向报文**的。发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付IP层。UDP对应用层交下来的报文，既不合并，也不拆分，而是**保留这些报文的边界**。这就是说，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文，如图5-4所示。在接收方的UDP，对IP层交上来的UDP用户数据报，在去除首部后就原封不动地交付上层的应用进程。也就是说，UDP一次交付一个完整的报文。因此，应用程序必须选择合适大小的报文。若报文太长，UDP把它交给IP层后，IP层在传送时可能要进行分片，这会降低IP层的效率。反之，若报文太短，UDP把它交给IP层后，会使IP数据报的首部的相对长度太大，这也降低了IP层的效率。
		- **![[Pasted image 20230807181018.png]]
	4. UDP**没有拥塞控制**，因此网络出现的拥塞不会使源主机的发送速率降低。这对某些实时应用是很重要的。很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许数据有太大的时延。UDP正好适合这种要求。
	5. UDP**支持一对一、一对多、多对一和多对多的交互通信**。
	6. UDP**的首部开销小**，只有8个字节，比TCP的20个字节的首部要短。
## 5.2.2 UDP的首部格式
- 用户数据报UDP有两个字段：数据字段和首部字段。首部字段很简单，只有8个字节（图5-5），由四个字段组成，**每个字段的长度都是两个字节** 。各字段意义如下：
	1. **源端口** 　源端口号。在需要对方回信时选用。不需要时可用全0。
	2. **目的端口** 　目的端口号。这在终点交付报文时必须使用。
	3. **长度** 　UDP用户数据报的长度，其最小值是8（仅有首部）。
	4. **检验和** 　检测UDP用户数据报在传输中是否有错。有错就丢弃。
	5. ![[Pasted image 20230807181355.png]]
- 当运输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交最后的终点——应用进程。图5-6是UDP基于端口分用的示意图。
	1. ![[Pasted image 20230807181414.png]]
- 如果接收方UDP发现收到的报文中的目的端口号不正确，就丢弃该报文，并由网际控制报文协议ICMP发送“端口不可达”差错报文给发送方。
- 虽然在UDP之间的通信要用到其端口号，但由于UDP的通信是无连接的，因此不需要使用套接字（TCP之间的通信必须要在两个套接字之间建立连接）。
- UDP计算检验和的方法和计算IP数据报首部检验和的方法相似。但不同的是：IP数据报的检验和只检验IP数据报的首部，但UDP的检验和是**把首部和数据部分一起都检验**。在发送方，首先是先把全零放入检验和字段。再把伪首部以及UDP用户数据报看成是由许多16位的字串接起来的。若UDP用户数据报的数据部分不是偶数个字节，则要填入一个全零字节（但此字节不发送）。然后按二进制反码计算出这些16位字的和。将此和的二进制反码写入检验和字段后，就发送这样的UDP用户数据报。在接收方，把收到的UDP用户数据报连同伪首部（以及可能的填充全零字节）一起，按二进制反码求这些16位字的和。当无差错时其结果应为全1。否则就表明有差错出现，接收方就应丢弃这个UDP用户数据报（也可以上交给应用层，但附上出现了差错的警告）。图5-7给出了一个计算UDP检验和的例子。这里假定用户数据报的长度是15字节，因此要添加一个全0的字节。读者可以自己检验一下在接收端是怎样对检验和进行检验的。不难看出，这种简单的差错检验方法的检错能力并不强，但它的好处是简单，处理起来较快。
	1. ![[Pasted image 20230807181600.png]]
# 5.3 传输控制协议TCP概述
## 5.3.1 TCP最主要的特点
- TCP最主要的特点：
	1. TCP是**面向连接的运输层协议**。应用程序在使用TCP协议之前，必须先建立TCP连接。在传送数据完毕后，必须释放已经建立的TCP连接。也就是说，应用进程之间的通信好像在“打电话”：通话前要先拨号建立连接，通话结束后要挂机释放连接。
	2. 每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）。
	3. TCP提供**可靠交付**的服务。通过TCP连接传送的数据，无差错、不丢失、不重复，并且按序到达。
	4. TCP提供**全双工通信**。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事，而TCP在合适的时候把数据发送出去。在接收时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。
	5. **面向字节流**。TCP中的“流”指的是**流入到进程或从进程流出的字节序列**。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据仅仅看成是一连串的**无结构的字节流**。TCP并不知道所传送的字节流的含义。TCP不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系（例如，发送方应用程序交给发送方的TCP共10个数据块，但接收方的TCP可能只用了4个数据块就把收到的字节流交付上层的应用程序）。但接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接收方的应用程序必须有能力识别收到的字节流，把它还原成有意义的应用层数据。
- TCP和UDP在发送报文时所采用的方式完全不同。TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP发送的报文长度是应用进程给出的）。如果应用进程传送到TCP缓存的数据块太长，TCP就可以把它划分短一些再传送。如果应用进程一次只发来一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。
## 5.3.2 TCP的连接
- TCP连接的端点不是主机，不是主机的IP地址，不是应用进程，也不是运输层的协议端口。TCP连接的端点叫做**套接字**或**插口**。
- **每一条TCP连接唯一地被通信两端的两个端点（即两个套接字）所确定**。即：
	1. ![[Pasted image 20230807210504.png]]
	2. 这里IP 1 和IP 2 分别是两个端点主机的IP地址，而port 1 和port 2 分别是两个端点主机中的端口号。TCP连接的两个套接字就是socket 1 和socket 2 。可见套接字socket是个很抽象的概念。
- **TCP连接的端点是个很抽象的套接字**，即（**IP地址：端口号** ）。同时，同一个IP地址可以有多个不同的TCP连接，而同一个端口号也可以出现在多个不同的TCP连接中。
- **同一个名词socket却可表示多种不同的意思**。例如：
	1. 允许应用程序访问连网协议的应**用编程接口API**，即运输层和应用层之间的一种接口，称为socket API，并简称为socket。
	2. 在socket API中使用的一个**函数名**也叫做socket。
	3. 调用socket函数的**端点**称为socket，如“创建一个数据报socket”。
	4. 调用socket函数时，其**返回值**称为socket描述符，可简称为socket。
	5. 在操作系统内核中连网协议的Berkeley实现，称为socket**实现**。
# 5.4 可靠传输的工作原理
- 理想的传输条件有以下两个特点：
	1. 传输信道不产生差错。
	2. 不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据。
## 5.4.1 停止等待协议
- **无差错情况**
	1. 停止等待协议可用图5-9来说明。图5-9（a）是最简单的无差错情况。A发送分组M 1 ，发完就暂停发送，等待B的确认。B收到了M 1 就向A发送确认。A在收到了对M 1 的确认后，就再发送下一个分组M 2 。同样，在收到B对M 2 的确认后，再发送M 3 。
		- ![[Pasted image 20230808145722.png]]
- **出现差错**
	1. 图5-9（b）是分组在传输过程中出现差错的情况。B接收M 1 时检测出了差错，就丢弃M 1 ，其他什么也不做。也可能是M 1 在传输过程中丢失了，这时B当然什么都不知道。在这两种情况下，B都不会发送任何信息。可靠传输协议是这样设计的：A只要超过了一段时间仍然没有收到确认，就认为刚才发送的分组丢失了，因而重传前面发送过的分组。这就叫做**超时重传**。要实现超时重传，就要在每发送完一个分组时设置一个超时计时器。如果在超时计时器到期之前收到了对方的确认，就撤销已设置的超时计时器。
	2. 应注意以下三点。
		- A在发送完一个分组后，**必须暂时保留已发送的分组的副本**。只有在收到相应的确认后才能清除暂时保留的分组副本。
		- 分组和确认分组都必须进行**编号。这样才能明确是哪一个发送出去的分组收到了确认，而哪一个分组还没有收到确认。
		- 超时计时器设置的重传时间**应当比数据在分组传输的平均往返时间更长一些**。图5-9（b）中的一段虚线表示如果M 1 正确到达B同时A也正确收到确认的过程。可见重传时间应设定为比平均往返时间更长一些。显然，如果重传时间设定得很长，那么通信的效率就会很低。但如果重传时间设定得太短，以致产生不必要的重传，就浪费了网络资源。然而，在运输层重传时间的准确设定是非常复杂的，这是因为已发送出的分组到底会**经过哪些网络**，以及这些网络将会**产生多大的时延**（这取决于这些网络**当时的拥塞情况**），这些都是**不确定因素**。
- **确认丢失和确认迟到**
	1. 图5-10（a）说明的是另一种情况。B所发送的对M 1 的确认丢失了。A在设定的超时重传时间内没有收到确认，并无法知道是自己发送的分组出错、丢失，或者是B发送的确认丢失了。因此A在超时计时器到期后就要重传M 1 。现在应注意B的动作。假定B又收到了重传的分组M 1 。
		- ![[Pasted image 20230808150213.png]]
	2. 这时应采取两个行动：
		- **丢弃这个重复的分组**M 1 ，不向上层交付。
		- **向A发送确认**。不能认为已经发送过确认就不再发送，因为A之所以重传M 1 就表示A没有收到对M 1 的确认。
	3. 图5-10（b）也是一种可能出现的情况。传输过程中没有出现差错，但B对分组M 1 的确认迟到了。A会收到重复的确认。对重复的确认的处理很简单：收下后就丢弃。B仍然会收到重复的M 1 ，并且同样要丢弃重复的M 1 ，并重传确认分组。
- **信道利用率**
	1. 停止等待协议的优点是简单，但缺点是信道利用率太低。我们可以用图5-11来说明这个问题。
		- ![[Pasted image 20230808150800.png]]
	2. 假定A发送分组需要的时间是T<sub>D</sub>。显然，TD 等于分组长度除以数据率。再假定分组正确到达B后，B处理分组的时间可以忽略不计，同时立即发回确认。假定B发送确认分组需要时间TA。如果A处理确认分组的时间也可以忽略不计，那么A在经过时间（TD＋RTT＋TA）后就可以再发送下一个分组，这里的RTT是往返时间。因为仅仅是在时间TD内才用来传送有用的数据（包括分组的首部），因此信道的利用率U可用下式计算：
		- ![[Pasted image 20230808150820.png]]
	3. 为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用**流水线传输**（如图5-12所示）。流水线传输就是发送方可连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认。这样可使信道上一直有数据不间断地在传送。显然，这种传输方式可以获得很高的信道利用率。
		- ![[Pasted image 20230808151106.png]]
## 5.4.2 连续ARQ协议
- 图5-13（a）表示发送方维持的**发送窗口**，它的意义是：位于发送窗口内的5个分组都可连续发送出去，而不需要等待对方的确认。这样，信道利用率就提高了。
	1. ![[Pasted image 20230808151146.png]]
- 连续ARQ协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。图5-13（b）表示发送方收到了对第1个分组的确认，于是把发送窗口向前移动一个分组的位置。如果原来已经发送了前5个分组，那么现在就可以发送窗口内的第6个分组了。
- 接收方一般都是采用**累积确认**的方式。这就是说，接收方不必对收到的分组逐个发送确认，而是在收到几个分组后，**对按序到达的最后一个分组发送确认**，这就表示：到这个分组为止的所有分组都已正确收到了。
- 累积确认有优点也有缺点。优点是：容易实现，即使确认丢失也不必重传。但缺点是不能向发送方反映出接收方已经正确收到的所有分组的信息。
# 5.5 TCP报文段的首部格式
- TCP虽然是面向字节流的，但TCP传送的数据单元却是报文段。一个TCP报文段分为首部和数据两部分，而TCP的全部功能都体现在它首部中各字段的作用。
- TCP报文段首部的前20个字节是固定的（图5-14），后面有4_n_ 字节是根据需要而增加的选项（_n_ 是整数）。因此TCP首部的最小长度是20字节。
	1. ![[Pasted image 20230808151426.png]]
- 首部固定部分各字段的意义如下：
	1. **源端口和目的端口** 　各占2个字节，分别写入源端口号和目的端口号。
	2. **序号** 　占4字节。序号范围是［0，2 32 –1］，共2 32 （即4 294 967 296）个序号。序号增加到2 32 –1后，下一个序号就又回到0。也就是说，序号使用mod 2 32 运算。TCP是面向字节流的。在一个TCP连接中传送的字节流中的**每一个字节都按顺序编号**。整个要传送的字节流的起始序号必须在连接建立时设置。首部中的序号字段值则指的是**本报文段**所发送的数据的第一个字节的序号。例如，一报文段的序号字段值是301，而携带的数据共有100字节。这就表明：本报文段的数据的第一个字节的序号是301，最后一个字节的序号是400。显然，下一个报文段（如果还有的话）的数据序号应当从401开始，即下一个报文段的序号字段值应为401。这个字段的名称也叫做“**报文段序号**”。
	3. **确认号** 　占4字节，是**期望收到对方下一个报文段的第一个数据字节的序号**。例如，B正确收到了A发送过来的一个报文段，其序号字段值是501，而数据长度是200字节（序号501～700），这表明B正确收到了A发送的到序号700为止的数据。因此，B期望收到A的下一个数据序号是701，于是B在发送给A的确认报文段中把确认号置为701。请注意，现在的确认号不是501，也不是700，而是701。总之，应当记住：若确认号＝*N*，则表明：到序号*N*–1为止的所有数据都已正确收到。
	4. **数据偏移** 　占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。这个字段实际上是指出TCP报文段的首部长度。由于首部中还有长度不确定的选项字段，因此数据偏移字段是必要的。但应注意，“数据偏移”的单位是32位字（即以4字节长的字为计算单位）。由于4位二进制数能够表示的最大十进制数字是15，因此数据偏移的最大值是60字节，这也是TCP首部的最大长度（即选项长度不能超过40字节）。
	5. **保留** 　占6位，保留为今后使用，但目前应置为0。
	6. **紧急** URG　当URG＝1时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送（相当于高优先级的数据），而不要按原来的排队顺序来传送。例如，已经发送了很长的一个程序要在远地的主机上运行。但后来发现了一些问题，需要取消该程序的运行。因此用户从键盘发出中断命令。如果不使用紧急数据，那么这两个字符将存储在接收TCP的缓存末尾。只有在所有的数据被处理完毕后这两个字符才被交付接收方的应用进程。这样做就浪费了许多时间；当URG置1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的**最前面**，而在紧急数据后面的数据仍是普通数据。这时要与首部中**紧急指针**字段配合使用。
	7. **确认** ACK　仅当ACK＝1时确认号字段才有效。当ACK＝0时，确认号无效。TCP规定，在连接建立后所有传送的报文段都必须把ACK置1。
	8. **推送** PSH　当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能够收到对方的响应。在这种情况下，TCP就可以使用推送操作。这时，发送方TCP把PSH置1，并立即创建一个报文段发送出去。接收方TCP收到PSH＝1的报文段，就尽快地（即“推送”向前）交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。
	9. **复位** RST　当RST＝1时，表明TCP连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。RST置1还用来拒绝一个非法的报文段或拒绝打开一个连接。RST也可称为重建位或重置位。
	10. **同步** SYN　在连接建立时用来同步序号。当SYN＝1而ACK＝0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN＝1和ACK＝1。因此，SYN置为1就表示这是一个连接请求或连接接受报文。
	11. **终止** FIN　用来释放一个连接。当FIN＝1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。
	12. **窗口** 　占2字节。窗口值是［0，2 16 –1］之间的整数。窗口指的是发送本报文段的一方的**接收窗口** （而不是自己的发送窗口）。窗口值**告诉对方** ：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量（以字节为单位）。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，**窗口值作为接收方让发送方设置其发送窗口的依据**。总之，应当记住：窗口字段明确指出了现在允许对方发送的数据量。窗口值经常在动态变化着。
	13. **检验和** 　占2字节。检验和字段检验的范围包括首部和数据这两部分。和UDP用户数据报一样，在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。伪首部的格式与图5-5中UDP用户数据报的伪首部一样。但应把伪首部第4个字段中的17改为6（TCP的协议号是6），把第5字段中的UDP长度改为TCP长度。接收方收到此报文段后，仍要加上这个伪首部来计算检验和。若使用IPv6，则相应的伪首部也要改变。
	14. **紧急指针** 　占2字节。紧急指针仅在URG＝1时才有意义，它指出本报文段中的紧急数据的字节数（紧急数据结束后就是普通数据）。因此，紧急指针指出了紧急数据的末尾在报文段中的位置。当所有紧急数据都处理完时，TCP就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为零时也可发送紧急数据。
	15. **选项** 　长度可变，最长可达40字节。当没有使用“选项”时，TCP的首部长度是20字节。
- TCP最初只规定了一种选项，即**最大报文段长度** MSS。MSS是每一个TCP报文段中的**数据字段的最大长度**。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是整个TCP报文段的最大长度，而是“TCP报文段长度减去TCP首部长度”。
- 随着互联网的发展，又陆续增加了几个选项。如**窗口扩大**选项、**时间戳**选项等。以后又增加了有关**选择确认**选项。这些选项的位置都在图5-14所示的选项字段中。
	1.  窗口扩大选项
		- 窗口扩大选项是为了扩大窗口。我们知道，TCP首部中窗口字段长度是16位，因此最大的窗口大小为64K字节。虽然这对早期的网络是足够用的，但对于包含卫星信道的网络，传播时延和带宽都很大，要获得高吞吐率需要更大的窗口大小。
		- 窗口扩大选项占3字节，其中有一个字节表示移位值S。新的窗口值等于TCP首部中的窗口位数从16增大到（16＋S）。移位值允许使用的最大值是14，相当于窗口最大值增大到2 （16＋14） –1＝2 30 –1。
		- 窗口扩大选项可以在双方初始建立TCP连接时进行协商。如果连接的某一端实现了窗口扩大，当它不再需要扩大其窗口时，可发送S＝0的选项，使窗口大小回到16。
	2. 时间戳选项
		- **时间戳**选项占10字节，其中最主要的字段是**时间戳**值字段（4字节）和**时间戳回送回答**字段（4字节）。时间戳选项有以下两个功能：
			1. 用来计算往返时间RTT。发送方在发送报文段时把当前时钟的时间值放入时间戳字段，接收方在确认该报文段时把时间戳字段值复制到时间戳回送回答字段。因此，发送方在收到确认报文后，可以准确地计算出RTT来。
			2. 用于处理TCP序号超过2 32 的情况，这又称为**防止序号绕回** PAWS。TCP报文段的序号只有32位，而每增加2 32 个序号就会重复使用原来用过的序号。当使用高速网络时，在一次TCP连接的数据传送中序号很可能会被重复使用。
# 5.6 TCP可靠传输的实现
## 5.6.1 以字节为单位的滑动窗口
- TCP的滑动窗口是以字节为单位的。为了便于说明滑动窗口的工作原理，把后面图5-15至图5-18中的字节编号都取得很小。现假定A收到了B**发来**的确认报文段，其中窗口是20字节，而确认号是31（这表明B期望收到的下一个序号是31，而序号30为止的数据已经收到了）。根据这两个数据，A就构造出自己的发送窗口，如图5-15所示。
	1. ![[Pasted image 20230808160923.png]]
- A发送窗口表示：在没有收到B的确认的情况下，A可以连续把窗口内的数据都发送出去。凡是已经发送过的数据，在未收到确认之前都必须暂时保留，以便在超时重传时使用。
- 发送窗口里面的序号表示允许发送的序号。显然，窗口越大，发送方就可以在收到对方确认之前连续发送更多的数据，因而可能获得更高的传输效率。接收方会把自己的接收窗口数值放在窗口字段中发送给对方。因此，A的发送窗口一定不能超过B的接收窗口数值。
- 发送窗口后沿的后面部分表示已发送且已收到了确认。这些数据显然不需要再保留了。而发送窗口前沿的前面部分表示不允许发送的，因为接收方都没有为这部分数据保留临时存放的缓存空间。
- 发送窗口的位置由窗口前沿和后沿的位置共同确定。发送窗口后沿的变化情况有两种可能，即不动（没有收到新的确认）和前移（收到了新的确认）。发送窗口后沿不可能向后移动，因为不能撤销掉已收到的确认。发送窗口前沿通常是不断向前移动，但也有可能不动。这对应于两种情况：一是没有收到新的确认，对方通知的窗口大小也不变；二是收到了新的确认但对方通知的窗口缩小了，使得发送窗口前沿正好不动。
- 发送窗口前沿也有可能**向后收缩**。这发生在对方通知的窗口缩小了。但TCP的标准**强烈不赞成这样做**。因为很可能发送方在收到这个通知以前已经发送了窗口中的许多数据，现在又要收缩窗口，不让发送这些数据，这样就会产生一些错误。
- 发送方的应用进程把字节流写入TCP的发送缓存，接收方的应用进程从TCP的接收缓存中读取字节流。图5-19画出了发送方维持的发送缓存和发送窗口，以及接收方维持的接收缓存和接收窗口。
	1. ![[Pasted image 20230808161130.png]]
	2. 图5-19（a）所示的发送方的情况，发送缓存用来暂时存放：
		- 发送应用程序传送给发送方TCP准备发送的数据
		- TCP已发送出但尚未收到确认的数据
	3. 图5-19（b）所示的接收方的情况，接收缓存用来暂时存放：
		- 按序到达的、但尚未被接收应用程序读取的数据
		- 未按序到达的数据。
- 再强调以下三点：
	1. 虽然A的发送窗口是根据B的接收窗口设置的，但在同一时刻，A的发送窗口并不总是和B的接收窗口一样大。这是因为通过网络传送窗口值需要经历一定的时间滞后（这个时间还是不确定的）。
	2. 对于不按序到达的数据应如何处理，TCP标准并无明确规定。如果接收方把不按序到达的数据一律丢弃，那么接收窗口的管理将会比较简单，但这样做对网络资源的利用不利（因为发送方会重复传送较多的数据）。因此TCP通常对不按序到达的数据是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再**按序交付上层的应用进程**。
	3. TCP要求接收方必须有累积确认的功能，这样可以减小传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据要发送时把确认信息顺便**捎带**上。注意两点。一是接收方不应过分推迟发送确认，否则会导致发送方不必要的重传，这反而浪费了网络的资源。TCP标准规定，确认推迟的时间不应超过0.5秒。若收到一连串具有最大长度的报文段，则必须每隔一个报文段就发送一个确认。二是捎带确认实际上并不经常发生，因为大多数应用程序很少同时在两个方向上发送数据。
- TCP的通信是全双工通信。通信中的每一方都在发送和接收报文段。因此，每一方都有自己的发送窗口和接收窗口。在谈到这些窗口时，一定要弄清是哪一方的窗口。
## 5.6.2 超时重传时间的选择
- 由于TCP的下层是互联网环境，发送的报文段可能只经过一个高速率的局域网，也可能经过多个低速率的网络，并且每个IP数据报所选择的路由还可能不同。如果把超时重传时间设置得太短，就会引起很多报文段的不必要的重传，使网络负荷增大。但若把超时重传时间设置得过长，则又使网络的空闲时间增大，降低了传输效率。
- TCP采用了一种自适应算法，它记录一个报文段发出的时间，以及收到相应的确认的时间。这两个时间之差就是**报文段的往返时间RTT** 。TCP保留了RTT的一个**加权平均往返时间** RTT S （这又称为平滑的往返时间，S表示Smoothed。因为进行的是加权平均，因此得出的结果更加平滑）。每当第一次测量到RTT样本时，RTT S 值就取为所测量到的RTT样本值。但以后每测量到一个新的RTT样本，就按下式重新计算一次RTT S ：
	1. ![[Pasted image 20230808162046.png]]
- 在上式中，0≤α<1。若α很接近于零，表示新的RTT S 值和旧的RTT S 值相比变化不大，而对新的RTT样本影响不大（RTT值更新较慢）。若选择α接近于1，则表示新的RTT S 值受新的RTT样本的影响较大（RTT值更新较快）。已成为建议标准的RFC 6298推荐的α值为1/8，即0.125。用这种方法得出的加权平均往返时间RTT S 就比测量出的RTT值更加平滑。
- 显然，超时计时器设置的**超时重传时间** RTO（RetransmissionTime-Out）应略大于上面得出的加权平均往返时间RTT S 。RFC 6298建议使用下式计算RTO：
	1. ![[Pasted image 20230808162104.png]]
- 而RTT D 是RTT的**偏差** 的加权平均值，它与RTT S 和新的RTT样本之差有关。RFC 6298建议这样计算RTT D 。当第一次测量时，RTT D 值取为测量到的RTT样本值的一半。在以后的测量中，则使用下式计算加权平均的RTT D ：
	1. ![[Pasted image 20230808162116.png]]
- 如图5-20所示，发送出一个报文段，设定的重传时间到了，还没有收到确认。于是重传报文段。经过了一段时间后，收到了确认报文段。现在的问题是：**如何判定此确认报文段是对先发送的报文段的确认，还是对后来重传的报文段的确认** 由于重传的报文段和原来的报文段完全一样，因此源主机在收到确认后，就无法做出正确的判断，而正确的判断对确定加权平均RTT S 的值关系很大。
	1. ![[Pasted image 20230808162135.png]]
	2. 若收到的确认是对重传报文段的确认，但却被源主机当成是对原来的报文段的确认，则这样计算出的RTT S 和超时重传时间RTO就会偏大。若后面再发送的报文段又是经过重传后才收到确认报文段，则按此方法得出的超时重传时间RTO就越来越长；同样，若收到的确认是对原来的报文段的确认，但被当成是对重传报文段的确认，则由此计算出的RTT S 和RTO都会偏小。这就必然导致报文段过多地重传。这样就有可能使RTO越来越短。
	4. Karn提出了一个算法：**在计算加权平均RTTS时，只要报文段重传了，就不采用其往返时间样本。这样得出的加权平均RTTS和RTO就较准确**。
	5. 但是，这又引起新的问题。设想出现这样的情况：报文段的时延突然增大了很多。因此在原来得出的重传时间内，不会收到确认报文段。于是就重传报文段。但根据Karn算法，不考虑重传的报文段的往返时间样本。这样，超时重传时间就无法更新。
	6. 因此要对Karn算法进行修正。方法是：报文段每重传一次，就把超时重传时间RTO增大一些。典型的做法是取新的重传时间为旧的重传时间的2倍。当不再发生报文段的重传时，才根据上面给出的（5-5）式计算超时重传时间。实践证明，这种策略较为合理。
	7. 总之，Karn算法能够使运输层区分开有效的和无效的往返时间样本，从而改进了往返时间的估测，使计算结果更加合理。
## 5.6.3 选择确认SACK
- 用一个例子来说明**选择确认**的工作原理。TCP的接收方在接收对方发送过来的数据字节流的序号不连续，结果就形成了一些不连续的字节块（如图5-21所示）。可以看出，序号1～1000收到了，但序号1001～1500没有收到。接下来的字节流又收到了，可是又缺少了3001～3500。再后面从序号4501起又没有收到。也就是说，接收方收到了和前面的字节流不连续的两个字节块。如果这些字节的序号都在接收窗口之内，那么接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方不要再重复发送这些已收到的数据。
	1. ![[Pasted image 20230808162315.png]]
	2. 从图5-21可看出，和前后字节不连续的每一个字节块都有两个边界：左边界和右边界。因此在图中用四个指针标记这些边界。第一个字节块的左边界L 1 ＝1501，但右边界R 1 ＝3001而不是3000。这就是说，左边界指出字节块的第一个字节的序号，但右边界减1才是字节块中的最后一个序号。同理，第二个字节块的左边界L 2 ＝3501，而右边界R 2 ＝4501。
# 5.7 TCP的流量控制
## 5.7.1 利用滑动窗口实现流量控制
- **流量控制**就是**让发送方的发送速率不要太快，要让接收方来得及接收**。
- **发送方的发送窗口不能超过接收方给出的接收窗口的数值**。
- TCP的**窗口单位是字节，不是报文段**。
- TCP为每一个连接设有一个**持续计时器**。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口**探测报文段**（仅携带1字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。如果窗口仍然是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口不是零，那么死锁的僵局就可以打破了。
## 5.7.2 TCP的传输效率
- 可以用不同的机制来控制TCP报文段的发送时机：
	1. TCP维持一个变量，它等于**最大报文段长度** MSS。只要缓存中存放的数据达到MSS字节时，就组装成一个TCP报文段发送出去。
	2. 由发送方的应用进程指明要求发送报文段，即TCP支持的**推送**操作。第三种机制是发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段（但长度不能超过MSS）发送出去。
- 在TCP的实现中广泛使用Nagle算法。算法如下：
	1. 若发送应用进程把要发送的数据逐个字节地送到TCP的发送缓存，则发送方就把第一个数据字节先发送出去，把后面到达的数据字节都缓存起来。
	2. 当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。
	3. 只有在收到对前一个报文段的确认后才继续发送下一个报文段。当数据到达较快而网络速率较慢时，用这样的方法可明显地减少所用的网络带宽。
	4. 当到达的数据已达到发送窗口大小的一半或已达到报文段的最大长度时，就立即发送一个报文段。这样做，就可以有效地提高网络的吞吐量。
- **糊涂窗口综合征**，有时也会使TCP的性能变坏。设想一种情况：TCP接收方的缓存已满，而交互式的应用进程一次只从接收缓存中读取1个字节（这样就使接收缓存空间仅腾出1个字节），然后向发送方发送确认，并把窗口设置为1个字节（但发送的数据报是40字节长）。接着，发送方又发来1个字节的数据（请注意，发送方发送的IP数据报是41字节长）。接收方发回确认，仍然将窗口设置为1个字节。这样进行下去，使网络的效率很低。
- 解决糊涂窗口综合征需要**让接收方等待一段时间**，使得或者接收缓存已有足够空间容纳一个最长的报文段，或者**等到接收缓存已有一半空闲的空间**。只要出现这两种情况之一，接收方就发出确认报文，并向发送方通知当前的窗口大小。此外，发送方也不要发送太小的报文段，而是把数据积累成足够大的报文段，或达到接收方缓存的空间的一半大小。
# 5.8 TCP的拥塞控制
## 5.8.1 拥塞控制的一般原理
- 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫做**拥塞**。可以把出现网络拥塞的条件写成如下的关系式：
	1. ![[Pasted image 20230809093124.png]]
- 若网络中有许多资源同时呈现供应不足，网络的性能就要明显变坏，整个网络的吞吐量将随输入负荷的增大而下降。
- 网络拥塞往往是由许多因素引起的：
	1. 当某个结点缓存的容量太小时，到达该结点的分组因无存储空间暂存而不得不被丢弃。现在设想将该结点缓存的容量扩展到非常大，于是凡到达该结点的分组均可在结点的缓存队列中排队，不受任何限制。
	2. 由于输出链路的容量和处理机的速度并未提高，因此在这队列中的绝大多数分组的排队等待时间将会大大增加，结果上层软件只好把它们进行重传（因为早就超时了）。
	3. 处理机处理的速率太慢可能引起网络的拥塞。
	4. 拥塞常常趋于恶化。如果一个路由器没有足够的缓存空间，它就会丢弃一些新到的分组。但当分组被丢弃时，发送这一分组的源点就会重传这一分组，甚至可能还要重传多次。这样会引起更多的分组流入网络和被网络中的路由器丢弃。
- **拥塞控制**是**防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载**。拥塞控制所要做的都有一个前提，就是**网络能够承受现有的网络负荷**。拥塞控制是一个**全局性的过程**，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。但TCP连接的端点只要迟迟不能收到对方的确认信息，就猜想在当前网络中的某处很可能发生了拥塞，但这时却无法知道拥塞到底发生在网络的何处，也无法知道发生拥塞的具体原因。
- **流量控制往往是指点对点通信量的控制**，是个**端到端**的问题（接收端控制发送端）。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。
- 进行拥塞控制需要付出代价。这首先需要获得网络内部流量分布的信息。在实施拥塞控制时，还需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样就产生了额外开销。拥塞控制有时需要将一些资源（如缓存、带宽等）分配给个别用户（或一些类别的用户）单独使用，这样就使得网络资源不能更好地实现共享。
- 拥塞控制所起的作用![[Pasted image 20230809093722.png]]
	1. 在图5-23中的横坐标是**提供的负载**，代表单位时间内输入给网络的分组数目。因此提供的负载也称为**输入负载**或**网络负载**。纵坐标是**吞吐量**，代表单位时间内从网络输出的分组数目。
	2. 具有理想拥塞控制的网络，在吞吐量饱和之前，网络吞吐量应等于提供的负载，故吞吐量曲线是45°的斜线。但当提供的负载超过某一限度时，由于网络资源受限，吞吐量不再增长而保持为水平线，即吞吐量达到饱和。这就表明提供的负载中有一部分损失掉了（例如，输入到网络的某些分组被某个结点丢弃了）。
	3. 实际网络的情况就很不相同了。从图5-23可看出，随着提供的负载的增大，网络吞吐量的增长速率逐渐减小。也就是说，在网络吞吐量还未达到饱和时，就已经有一部分的输入分组被丢弃了。当网络的吞吐量明显地小于理想的吞吐量时，网络就进入了**轻度拥塞**的状态。更值得注意的是，当提供的负载达到某一数值时，网络的吞吐量反而随提供的负载的增大而下降，这时**网络就进入了拥塞状态**。当提供的负载继续增大到某一数值时，网络的吞吐量就下降到零，网络已无法工作，这就是所谓的**死锁**。
- 从原理上讲，寻找拥塞控制的方案无非是寻找使不等式（5-7）不再成立的条件。这或者是增大网络的某些可用资源（如业务繁忙时增加一些链路，增大链路的带宽，或使额外的通信量从另外的通路分流），或减少一些用户对某些资源的需求（如拒绝接受新的建立连接的请求，或要求用户减轻其负荷，这属于降低服务质量）。
- 开环控制就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。但一旦整个系统运行起来，就不再中途进行改正了。
- 闭环控制是基于反馈环路的概念，主要有以下几种措施：
	1. 监测网络系统以便检测到拥塞在何时、何处发生。
	2. 把拥塞发生的信息传送到可采取行动的地方。
	3. 调整网络系统的运行以解决出现的问题。
- 过于频繁地采取行动以缓和网络的拥塞，会使系统产生不稳定的振荡。但过于迟缓地采取行动又不具有任何实用价值。
## 5.8.2 TCP的拥塞控制方法
- TCP进行拥塞控制的算法有四种，即**慢开始**、**拥塞避免**、**快重传**和**快恢复**。
- 发送方维持一个叫做**拥塞窗口** cwnd的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。**发送方让自己的发送窗口等于拥塞窗口**。
- 发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就可以再增大一些，以便把更多的分组发送出去，这样就可以提高网络的利用率。但只要网络出现拥塞或有可能出现拥塞，就必须把拥塞窗口减小一些，以减少注入到网络中的分组数，以便缓解网络出现的拥塞。
- **慢开始**算法的思路是这样的：当主机开始发送数据时，由于并不清楚网络的负荷情况，所以如果立即把大量数据字节注入到网络，那么就有可能引起网络发生拥塞。经验证明，较好的方法是先探测一下，即**由小到大逐渐增大发送窗口** ，也就是说，**由小到大逐渐增大拥塞窗口数值**。
- 旧的规定是这样的：在刚刚开始发送报文段时，先把初始拥塞窗口cwnd设置为1至2个发送方的最大报文段SMSS的数值，但新的RFC 5681把初始拥塞窗口cwnd设置为不超过2至4个SMSS的数值。具体的规定如下：
	1. 若SMSS>2190字节，则设置初始拥塞窗口cwnd＝2×SMSS字节，且**不得超过**2个报文段。
	2. 若（SMSS>1095字节）且（SMSS≤2190字节），则设置初始拥塞窗口cwnd＝3×SMSS字节，且**不得超过**3个报文段。
	3. 若SMSS≤1095字节，则设置初始拥塞窗口cwnd＝4×SMSS字节，且**不得超过**4个报文段。
- 慢开始规定，在每收到一个**对新的报文段的确认**后，可以把拥塞窗口增加最多一个SMSS的数值。
	1. ![[Pasted image 20230809102613.png]]
	2. 其中*N*是原先未被确认的、但现在被刚收到的确认报文段所确认的字节数。
- 在一开始发送方先设置cwnd＝1，发送第一个报文段M 1 ，接收方收到后确认M 1 。发送方收到对M 1 的确认后，把cwnd从1增大到2，于是发送方接着发送M 2 和M 3 两个报文段。接收方收到后发回对M 2 和M 3 的确认。发送方每收到一个**对新报文段的确认**（重传的不算在内）就使发送方的拥塞窗口加1，因此发送方在收到两个确认后，cwnd就从2增大到4，并可发送M 4 ～M 7 共4个报文段（见图5-24）。因此使用慢开始算法后，**每经过一个传输轮次**，**拥塞窗口** cwnd**就加倍**。
	1. ![[Pasted image 20230809102703.png]]
- 传输**轮次**。从图5-24可以看出，一个传输轮次所经历的时间其实就是往返时间RTT（请注意，RTT并非是恒定的数值）。使用“传输轮次”是更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。例如，拥塞窗口cwnd的大小是4个报文段，那么这时的往返时间RTT就是发送方连续发送4个报文段，并收到这4个报文段的确认，总共经历的时间。
- 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个**慢开始门限** ssthresh状态变量。慢开始门限ssthresh的用法如下：
	1. 当cwnd<ssthresh时，使用上述的慢开始算法。
	2. 当cwnd>ssthresh时，停止使用慢开始算法而改用拥塞避免算法。
	3. 当cwnd＝ssthresh时，既可使用慢开始算法，也可使用拥塞避免算法。
- **拥塞避免**算法的思路是让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是像慢开始阶段那样加倍增长。因此在拥塞避免阶段就有“**加法增大** ”AI的特点。这表明在拥塞避免阶段，拥塞窗口cwnd**按线性规律缓慢增长**，比慢开始算法的拥塞窗口增长速率缓慢得多。
- 采用快重传算法可以让发送方**尽早知道发生了个别报文段的丢失**。快重传算法首先要求接收方不要等待自己发送数据时才进行捎带确认，而是要**立即发送确认**，即使收到了**失序的报文段**也要立即发出对已收到的报文段的重复确认。
- 快重传算法规定，发送方只要**一连收到3个重复确认**，就知道接收方确实没有收到报文段M 3 ，因而应当**立即进行重传**（即“快重传”），这样就不会出现超时，发送方也不就会误认为出现了网络拥塞。使用快重传可以使整个网络的吞吐量提高约20％。
- TCP的拥塞控制可以归纳为图5-27的流程图。
	1. ![[Pasted image 20230809102925.png]]
- 实际上接收方的缓存空间总是有限的。接收方根据自己的接收能力设定了接收方窗口rwnd，并把这个窗口值写入TCP首部中的窗口字段，传送给发送方。因此，**接收方窗口** 又称为**通知窗口**。因此，从接收方对发送方的流量控制的角度考虑，**发送方的发送窗口一定不能超过对方给出的接收方窗口值** rwnd。
- 如果把拥塞控制和接收方对发送方的流量控制一起考虑，那么很显然，发送方的窗口的上限值应当取为接收方窗口rwnd和拥塞窗口cwnd这两个变量中较小的一个，也就是说：
	1. ![[Pasted image 20230809103014.png]]
	2. 当rwnd<cwnd时，是接收方的接收能力限制发送方窗口的最大值。
	3. 反之，当cwnd<rwnd时，则是网络的拥塞程度限制发送方窗口的最大值。
	4. 也就是说，rwnd和cwnd中数值较小的一个，控制了发送方发送数据的速率。
## 5.8.3 主动队列管理AQM
- 网络层的策略对TCP拥塞控制影响最大的就是路由器的分组丢弃策略。在最简单的情况下，路由器的队列通常都是按照“**先进先出** ”FIFO的规则处理到来的分组。由于队列长度总是有限的，因此当队列已满时，以后再到达的所有分组（如果能够继续排队，这些分组都将排在队列的尾部）将都被丢弃。这就叫做**尾部丢弃策略**。
- 路由器的尾部丢弃往往会导致一连串分组的丢失，这就使发送方出现超时重传，使TCP进入拥塞控制的慢开始状态，结果使TCP连接的发送方突然把数据的发送速率降低到很小的数值。更为严重的是，在网络中通常有很多的TCP连接（它们有不同的源点和终点），这些连接中的报文段通常是复用在网络层的IP数据报中传送。在这种情况下，若发生了路由器中的尾部丢弃，就可能会同时影响到很多条TCP连接，结果使这许多TCP连接**在同一时间**突然都进入到慢开始状态。这在TCP的术语中称为**全局同步**。全局同步使得全网的通信量突然下降了很多，而在网络恢复正常后，其通信量又突然增大很多。
- 为了避免发生网络中的全局同步现象，提出了**主动队列管理** AQM。所谓“主动”就是不要等到路由器的队列长度已经达到最大值时才不得不丢弃后面到达的分组。应当在队列长度达到某个值得警惕的数值时（即当网络拥塞有了某些拥塞征兆时），就主动丢弃到达的分组。这样就提醒了发送方放慢发送的速率，因而有可能使网络拥塞的程度减轻，甚至不出现网络拥塞。
- 实现**随机早期检测** RED时需要使路由器维持两个参数，即队列长度最小门限和最大门限。当每一个分组到达时，RED就按照规定的算法先计算当前的平均队列长度。
	1. 若平均队列长度小于最小门限，则把新到达的分组放入队列进行排队。
	2. 若平均队列长度超过最大门限，则把新到达的分组丢弃。
	3. 若平均队列长度在最小门限和最大门限之间，则按照某一丢弃概率*p*把新到达的分组丢弃（这就体现了丢弃分组的随机性）。
- RED不是等到已经发生网络拥塞后才把所有在队列尾部的分组全部丢弃，而是在检测到网络拥塞的**早期征兆**时（即路由器的平均队列长度达到一定数值时），就以概率*p*丢弃个别的分组，让拥塞控制只在个别的TCP连接上进行，因而避免发生全局性的拥塞控制。
# 5.9 TCP的运输连接管理
- TCP是面向连接的协议。运输连接是用来传送TCP报文的。TCP运输连接的建立和释放是每一次面向连接的通信中必不可少的过程。因此，运输连接就有三个阶段，即：**连接建立、数据传送和连接释放**。运输连接的管理就是使运输连接的建立和释放都能正常地进行。
- TCP连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做**客户**，而被动等待连接建立的应用进程叫做**服务器**。
## 5.9.1 TCP的连接建立
- TCP建立连接的过程叫做握手，握手需要在客户和服务器之间交换三个TCP报文段。图5-28画出了三报文握手建立TCP连接的过程。
	1. ![[Pasted image 20230809153847.png]]
	2. A的TCP客户进程也是首先创建**传输控制模块** TCB。然后，在打算建立TCP连接时，向B发出连接请求报文段，这时首部中的同步位SYN＝1，同时选择一个初始序号seq＝x。TCP规定，SYN报文段（即SYN＝1的报文段）不能携带数据，但要**消耗掉一个序号**。这时，TCP客户进程进入SYN-SENT（同步已发送）状态。
	3. B收到连接请求报文段后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack＝x＋1，同时也为自己选择一个初始序号seq＝y。请注意，这个报文段也不能携带数据，但同样**要消耗掉一个序号**。这时TCP服务器进程进入SYN-RCVD（同步收到）状态。
	4. TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack＝y＋1，而自己的序号seq＝x＋1。TCP的标准规定，ACK报文段可以携带数据。但**如果不携带数据则不消耗序号**，在这种情况下，下一个数据报文段的序号仍是seq＝x＋1。这时，TCP连接已经建立，A进入ESTABLISHED（已建立连接）状态。
	5. 当B收到A的确认后，也进入ESTABLISHED状态。
## 5.9.2 TCP的链接释放
- 数据传输结束后，通信的双方都可释放连接。现在A和B都处于ESTABLISHED状态（图5-29）。A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位FIN置1，其序号seq＝u，它等于前面已传送过的数据的最后一个字节的序号加1。这时A进入FIN-WAIT-1（终止等待1）状态，等待B的确认。请注意，TCP规定，FIN报文段即使不携带数据，它也消耗掉一个序号。
	1. ![[NeatReader-1691566797507.png]]图5-29
	2. B收到连接释放报文段后即发出确认，确认号是ack＝u＋1，而这个报文段自己的序号是v，等于B前面已传送过的数据的最后一个字节的序号加1。然后B就进入CLOSE-WAIT（关闭等待）状态。TCP服务器进程这时应通知高层应用进程，因而从A到B这个方向的连接就释放了，这时的TCP连接处于**半关闭**状态，即A已经没有数据要发送了，但B若发送数据，A仍要接收。也就是说，从B到A这个方向的连接并未关闭，这个状态可能会持续一段时间。
	3. A收到来自B的确认后，就进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。
	4. 若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这时B发出的连接释放报文段必须使FIN＝1。现假定B的序号为w（在半关闭状态B可能又发送了一些数据）。B还必须重复上次已发送过的确认号ack＝u＋1。这时B就进入LAST-ACK（最后确认）状态，等待A的确认。
	5. A在收到B的连接释放报文段后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack＝w＋1，而自己的序号是seq＝u＋1（根据TCP标准，前面发送过的FIN报文段要消耗一个序号）。然后进入到TIME-WAIT（时间等待）状态。请注意，现在TCP连接还没有释放掉。必须经过**时间等待计时器**设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做**最长报文段寿命**，RFC 793建议设为2分钟。但这完全是从工程上来考虑的，对于现在的网络，MSL＝2分钟可能太长了一些。因此TCP允许不同的实现可根据具体情况使用更小的MSL值。因此，从A进入到TIME-WAIT状态后，要经过4分钟才能进入到CLOSED状态，才能开始建立下一个新的连接。当A撤销相应的传输控制块TCB后，就结束了这次的TCP连接。
## 5.9.3 TCP的有限状态机
- 为了更清晰地看出TCP连接的各种状态之间的关系，图5-30给出了TCP的有限状态机。图中每一个方框即TCP可能具有的状态。每个方框中的大写英文字符串是TCP标准所使用的TCP连接状态名。状态之间的箭头表示可能发生的状态变迁。箭头旁边的字，表明引起这种变迁的原因，或表明发生状态变迁后又出现什么动作。请注意图中有三种不同的箭头。粗实线箭头表示对客户进程的正常变迁。粗虚线箭头表示对服务器进程的正常变迁。另一种细线箭头表示异常变迁。
	1. ![[NeatReader-1691566885327.png]]
# 本章重要概念
- 运输层提供应用进程间的逻辑通信，也就是说，运输层之间的通信并不是真正在两个运输层之间直接传送数据。运输层向应用层屏蔽了下面网络的细节（如网络拓扑、所采用的路由选择协议等），它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道。
- 网络层为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信。
- 运输层有两个主要的协议：TCP和UDP。它们都有复用和分用，以及检错的功能。当运输层采用面向连接的TCP协议时，尽管下面的网络是不可靠的（只提供尽最大努力服务），但这种逻辑通信信道就相当于一条全双工通信的可靠信道。当运输层采用无连接的UDP协议时，这种逻辑通信信道仍然是一条不可靠信道。
- 运输层用一个16位端口号来标志一个端口。端口号只具有本地意义，它只是为了标志本计算机应用层中的各个进程在和运输层交互时的层间接口。在互联网的不同计算机中，相同的端口号是没有关联的。
- 两台计算机中的进程要互相通信，不仅要知道对方的IP地址（为了找到对方的计算机），而且还要知道对方的端口号（为了找到对方计算机中的应用进程）。
- 运输层的端口号分为服务器端使用的端口号（0～1023指派给熟知端口，1024～49151是登记端口号）和客户端暂时使用的端口号（49152～65535）。
- UDP的主要特点是：（1）无连接；（2）尽最大努力交付；（3）面向报文；（4）无拥塞控制；（5）支持一对一、一对多、多对一和多对多的交互通信；（6）首部开销小（只有四个字段：源端口、目的端口、长度、检验和）。
- TCP的主要特点是：（1）面向连接；（2）每一条TCP连接只能是点对点的（一对一）；（3）提供可靠交付的服务；（4）提供全双工通信；（5）面向字节流。
- TCP用主机的IP地址加上主机上的端口号作为TCP连接的端点。这样的端点就叫做套接字（socket）或插口。套接字用（IP地址：端口号）来表示。
- 停止等待协议能够在不可靠的传输网络上实现可靠的通信。每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。分组需要进行编号。
- 超时重传是指只要超过了一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求ARQ。
- 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。
- 连续ARQ协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组都可连续发送出去，而不需要等待对方的确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已正确收到了。
- TCP报文段首部的前20个字节是固定的，后面有4_N_ 字节是根据需要而增加的选项（_N_ 是整数）。在一个TCP连接中传送的字节流中的每一个字节都按顺序编号。首部中的序号字段值则指的是本报文段所发送的数据的第一个字节的序号。
- TCP首部中的确认号是期望收到对方下一个报文段的第一个数据字节的序号。若确认号为_N_ ，则表明：到序号_N_ –1为止的所有数据都已正确收到。
- TCP首部中的窗口字段指出了现在允许对方发送的数据量。窗口值是经常在动态变化着的。
- TCP使用滑动窗口机制。发送窗口里面的序号表示允许发送的序号。发送窗口后沿的后面部分表示已发送且已收到了确认，而发送窗口前沿的前面部分表示不允许发送。发送窗口后沿的变化情况有两种可能，即不动（没有收到新的确认）和前移（收到了新的确认）。发送窗口前沿通常是不断向前移动的。
- 流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。
- 在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫做拥塞。拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。
- 流量控制是一个端到端的问题，是接收端抑制发送端发送数据的速率，以便使接收端来得及接收。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。
- 为了进行拥塞控制，TCP的发送方要维持一个拥塞窗口cwnd的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接收窗口中较小的一个。
- TCP的拥塞控制采用了四种算法，即慢开始、拥塞避免、快重传和快恢复。在网络层，也可以使路由器采用适当的分组丢弃策略（如主动队列管理AQM），以减少网络拥塞的发生。
- 运输连接有三个阶段，即：连接建立、数据传送和连接释放。
- 主动发起TCP连接建立的应用进程叫做客户，而被动等待连接建立的应用进程叫做服务器。TCP的连接建立采用三报文握手机制。服务器要确认客户的连接请求，然后客户要对服务器的确认进行确认。
- TCP的连接释放采用四报文握手机制。任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后就进入半关闭状态。当另一方也没有数据再发送时，则发送连接释放通知，对方确认后就完全关闭了TCP连接。